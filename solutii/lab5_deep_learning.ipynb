{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 5: Deep Learning pentru Detectarea Intruziunilor\n",
    "\n",
    "## Obiective\n",
    "- Construirea unei rețele neurale MLP (Multi-Layer Perceptron)\n",
    "- Înțelegerea arhitecturii și hiperparametrilor\n",
    "- Antrenarea și evaluarea modelului\n",
    "- (Bonus) Implementarea LSTM pentru date secvențiale\n",
    "\n",
    "## Dataset\n",
    "Vom folosi datele preprocesate din laboratoarele anterioare sau un subset din CIC-IDS2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup și Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalare dependențe (doar în Colab)\n",
    "# !pip install tensorflow pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                            f1_score, confusion_matrix, classification_report)\n",
    "\n",
    "# Setări\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponibil: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Încărcarea Datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Încărcăm datele\n",
    "try:\n",
    "    X_train = np.load('X_train.npy')\n",
    "    X_test = np.load('X_test.npy')\n",
    "    y_train = np.load('y_train.npy')\n",
    "    y_test = np.load('y_test.npy')\n",
    "    print(\"Date încărcate din fișiere!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Creăm date sintetice...\")\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    X, y = make_classification(\n",
    "        n_samples=20000, n_features=38, n_informative=25,\n",
    "        n_redundant=8, n_classes=2, weights=[0.5, 0.5],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri\n",
    "n_features = X_train.shape[1]\n",
    "n_classes = 2  # Binary classification: normal vs attack\n",
    "\n",
    "print(f\"Input shape: {n_features}\")\n",
    "print(f\"Output classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Layer Perceptron (MLP)\n",
    "\n",
    "### Arhitectură:\n",
    "- **Input Layer**: n_features neuroni\n",
    "- **Hidden Layer 1**: 128 neuroni + ReLU + Dropout\n",
    "- **Hidden Layer 2**: 64 neuroni + ReLU + Dropout\n",
    "- **Hidden Layer 3**: 32 neuroni + ReLU\n",
    "- **Output Layer**: 1 neuron + Sigmoid (pentru binary classification)\n",
    "\n",
    "### Componente:\n",
    "- **Dense**: Layer fully-connected\n",
    "- **ReLU**: Funcție de activare (Rectified Linear Unit)\n",
    "- **Dropout**: Regularizare (previne overfitting)\n",
    "- **BatchNormalization**: Normalizează output-ul între layere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model(input_dim):\n",
    "    \"\"\"\n",
    "    Creează un model MLP pentru clasificare binară.\n",
    "    \n",
    "    Args:\n",
    "        input_dim: Numărul de features de input\n",
    "    \n",
    "    Returns:\n",
    "        Model Keras compilat\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Input layer este implicit\n",
    "        \n",
    "        # Hidden Layer 1\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Hidden Layer 3\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Output Layer (binary classification)\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compilare\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Creăm modelul\n",
    "mlp_model = create_mlp_model(n_features)\n",
    "\n",
    "# Afișăm arhitectura\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    # Oprește antrenarea dacă validation loss nu se îmbunătățește\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Salvează cel mai bun model\n",
    "    ModelCheckpoint(\n",
    "        'best_mlp_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antrenare\n",
    "print(\"Antrenare MLP...\")\n",
    "\n",
    "history = mlp_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizare curbe de învățare\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training vs Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training vs Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluare pe test set\n",
    "print(\"\\nEvaluare MLP pe Test Set:\")\n",
    "\n",
    "# Predicții\n",
    "y_pred_proba = mlp_model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Metrici\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Matrice de confuzie\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Normal', 'Attack'],\n",
    "            yticklabels=['Normal', 'Attack'])\n",
    "plt.title('MLP - Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM (Long Short-Term Memory) - Bonus\n",
    "\n",
    "LSTM este o arhitectură de rețea neurală recurentă (RNN) care poate învăța dependențe pe termen lung.\n",
    "\n",
    "### De ce LSTM pentru securitate?\n",
    "- Traficul de rețea are natură secvențială (pachete în timp)\n",
    "- Atacurile pot avea pattern-uri temporale\n",
    "- LSTM poate \"ține minte\" context din trecut\n",
    "\n",
    "### Notă:\n",
    "Pentru a folosi LSTM, trebuie să restructurăm datele în format 3D: (samples, timesteps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructurăm datele pentru LSTM\n",
    "# Simulăm secvențe de lungime 1 (fiecare sample e o \"secvență\" de 1 timestep)\n",
    "# În practică, am grupa mai multe samples consecutive\n",
    "\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print(f\"Shape pentru LSTM: {X_train_lstm.shape}\")\n",
    "print(f\"(samples, timesteps, features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Creează un model LSTM pentru clasificare.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Tuple (timesteps, features)\n",
    "    \n",
    "    Returns:\n",
    "        Model Keras compilat\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # LSTM Layer\n",
    "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Al doilea LSTM Layer\n",
    "        LSTM(32, return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(32, activation='relu'),\n",
    "        \n",
    "        # Output\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Creăm modelul LSTM\n",
    "lstm_model = create_lstm_model((1, n_features))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antrenare LSTM\n",
    "print(\"Antrenare LSTM...\")\n",
    "\n",
    "lstm_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=lstm_callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluare LSTM\n",
    "print(\"\\nEvaluare LSTM pe Test Set:\")\n",
    "\n",
    "y_pred_lstm_proba = lstm_model.predict(X_test_lstm)\n",
    "y_pred_lstm = (y_pred_lstm_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test, y_pred_lstm)\n",
    "lstm_precision = precision_score(y_test, y_pred_lstm)\n",
    "lstm_recall = recall_score(y_test, y_pred_lstm)\n",
    "lstm_f1 = f1_score(y_test, y_pred_lstm)\n",
    "\n",
    "print(f\"Accuracy:  {lstm_accuracy:.4f}\")\n",
    "print(f\"Precision: {lstm_precision:.4f}\")\n",
    "print(f\"Recall:    {lstm_recall:.4f}\")\n",
    "print(f\"F1-Score:  {lstm_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparație MLP vs LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparație rezultate\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['MLP', 'LSTM'],\n",
    "    'Accuracy': [accuracy, lstm_accuracy],\n",
    "    'Precision': [precision, lstm_precision],\n",
    "    'Recall': [recall, lstm_recall],\n",
    "    'F1-Score': [f1, lstm_f1]\n",
    "})\n",
    "\n",
    "print(\"\\nComparație MLP vs LSTM:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Vizualizare\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison))\n",
    "width = 0.2\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors = ['steelblue', 'forestgreen', 'coral', 'purple']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, comparison[metric], width, label=metric, color=colors[i])\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparație Deep Learning Models')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(comparison['Model'])\n",
    "ax.legend()\n",
    "ax.set_ylim([0.8, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvarea Modelelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvăm modelele\n",
    "mlp_model.save('mlp_model.keras')\n",
    "lstm_model.save('lstm_model.keras')\n",
    "\n",
    "# Salvăm rezultatele\n",
    "comparison.to_csv('deep_learning_results.csv', index=False)\n",
    "\n",
    "# Salvăm istoricul antrenării\n",
    "with open('mlp_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"Modele și rezultate salvate!\")\n",
    "print(\"  - mlp_model.keras\")\n",
    "print(\"  - lstm_model.keras\")\n",
    "print(\"  - deep_learning_results.csv\")\n",
    "print(\"  - mlp_history.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rezumat\n",
    "\n",
    "### Ce am învățat:\n",
    "1. **MLP** - Rețea feedforward cu multiple layere dense\n",
    "   - Bun pentru date tabelare\n",
    "   - Rapid de antrenat\n",
    "   \n",
    "2. **LSTM** - Rețea recurentă cu memorie\n",
    "   - Bun pentru date secvențiale\n",
    "   - Mai complex, mai lent\n",
    "\n",
    "### Hiperparametri importanți:\n",
    "- `learning_rate`: Viteza de învățare (0.001 e un start bun)\n",
    "- `epochs`: Numărul de iterații\n",
    "- `batch_size`: Câte samples per update\n",
    "- `dropout`: Rata de dropout pentru regularizare\n",
    "\n",
    "### Tehnici anti-overfitting:\n",
    "- Dropout\n",
    "- BatchNormalization\n",
    "- EarlyStopping\n",
    "\n",
    "### Următorul pas:\n",
    "**Laborator 6** - Evaluare comparativă și vizualizare rezultate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
